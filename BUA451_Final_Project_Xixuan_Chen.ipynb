{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Packages & Environment Setup"
      ],
      "metadata": {
        "id": "GWxdyb9NmE_v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "gRKUg9RZYcF3"
      },
      "outputs": [],
      "source": [
        "!pip install pandas-gbq --quiet\n",
        "!pip install google-cloud-bigquery pandas\n",
        "!pip install --quiet google-cloud-bigquery\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import pandas as pd\n",
        "from pandas.io import gbq\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "from google.cloud import bigquery"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Executive Summary\n",
        "------------------\n",
        "This project explores the Bitcoin Cash blockchain by analyzing block-level data using BigQuery.\n",
        "Our primary objective was to build a predictive model that determines whether a block exceeds\n",
        "500KB in size based on metadata such as block version, number, and time since the previous block.\n",
        "\n",
        "After cleaning and preparing 5,000 rows of blockchain data, we trained a Decision Tree Classifier.\n",
        "The model achieved strong performance with an overall test accuracy of 91%.\n",
        "\n",
        "Key results:\n",
        "- Precision (for large blocks): 0.79\n",
        "- Recall (for large blocks): 0.80\n",
        "- F1-score (for large blocks): 0.79\n",
        "    \n",
        "The model demonstrates solid predictive power and highlights potential for deeper analysis\n",
        "on blockchain behavior using machine learning techniques. Future improvements could include\n",
        "tuning model hyperparameters, testing ensemble models, or analyzing trends across time windows."
      ],
      "metadata": {
        "id": "WRAsl08jPUmv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project Connection"
      ],
      "metadata": {
        "id": "7Oh1eR9ymPJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "project_id = 'proven-wavelet-457219-u4'\n",
        "client = bigquery.Client(project = project_id)"
      ],
      "metadata": {
        "id": "gnehczJUZW5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Description\n",
        "--------------------\n",
        "The dataset used in this project is sourced from BigQueryâ€™s public dataset:\n",
        "`bigquery-public-data.crypto_bitcoin_cash.blocks`.\n",
        "\n",
        "Each row in the dataset represents a block on the Bitcoin Cash blockchain.\n",
        "The following variables were selected for modeling:\n",
        "- size: The size of the block in bytes (used to create the target variable).\n",
        "- version: The block version number.\n",
        "- number: The block height (its position in the chain).\n",
        "- nonce: A value miners vary to find a valid hash (excluded from final model).\n",
        "- time_since_last_block: Time difference (in seconds) between this and the previous block.\n",
        "\n",
        "The target variable `label` was engineered as a binary indicator:\n",
        "- 1 if the block size > 500,000 bytes\n",
        "- 0 otherwise\n",
        "\n",
        "After filtering and cleaning, the final dataset contains 5,000 rows and 4 predictor features.\n",
        "This dataset was suitable for a binary classification task."
      ],
      "metadata": {
        "id": "RSaQTGv_P5Ya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "SELECT *\n",
        "FROM `bigquery-public-data.crypto_bitcoin_cash.blocks`\n",
        "LIMIT 10\n",
        "\"\"\"\n",
        "\n",
        "result = client.query(query).result().to_dataframe()\n",
        "result.head()"
      ],
      "metadata": {
        "id": "4OwG3nLTddVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA RESULTS and VISUALS"
      ],
      "metadata": {
        "id": "cB73URsNfn6z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Query 1: Block sizes over time"
      ],
      "metadata": {
        "id": "xPtvdYNPeZ6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query1 = \"\"\"\n",
        "SELECT\n",
        "  DATE(timestamp) AS date,\n",
        "  AVG(size) AS avg_block_size\n",
        "FROM `bigquery-public-data.crypto_bitcoin_cash.blocks`\n",
        "GROUP BY date\n",
        "ORDER BY date\n",
        "\"\"\"\n",
        "df1 = client.query(query1).result().to_dataframe()"
      ],
      "metadata": {
        "id": "c5Qc7y2reXQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "px.line(df1, x='date', y='avg_block_size', title='Average Block Size Over Time').show()"
      ],
      "metadata": {
        "id": "j5dvwv_RephB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The average Bitcoin block size has generally increased over time, especially from around 2013 to 2017, indicating greater transaction volume and network activity. However, there are noticeable sharp drops and volatility after 2017, suggesting changes in network behavior, possibly due to scaling solutions (like SegWit) or market events impacting transaction patterns"
      ],
      "metadata": {
        "id": "iSs5fb8m8QNl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Query 2: Number of blocks per day"
      ],
      "metadata": {
        "id": "JBSa2QaIeb20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query2 = \"\"\"\n",
        "SELECT\n",
        "  DATE(timestamp) AS date,\n",
        "  COUNT(*) AS block_count\n",
        "FROM `bigquery-public-data.crypto_bitcoin_cash.blocks`\n",
        "GROUP BY date\n",
        "ORDER BY date\n",
        "\"\"\"\n",
        "df2 = client.query(query2).result().to_dataframe()"
      ],
      "metadata": {
        "id": "H9IMnRjaeeUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "px.line(df2, x='date', y='block_count', title='Number of Blocks Per Day').show()"
      ],
      "metadata": {
        "id": "qDe-oUF0euS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The number of Bitcoin blocks mined per day has remained relatively stable over time, hovering around 150-200 blocks/day. However, there are occasional spikes, most notably around late 2017 to early 2018, when the number sharply increased to over 1200 blocks/day. This spike may reflect abnormal network behavior or testing phases, possibly linked to a hard fork, stress test, or sudden difficulty adjustments."
      ],
      "metadata": {
        "id": "Yc0ZwcZs9fbY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Query 3: Average time between blocks"
      ],
      "metadata": {
        "id": "gR5soXWUehie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query3 = \"\"\"\n",
        "WITH block_times AS (\n",
        "  SELECT\n",
        "    timestamp,\n",
        "    TIMESTAMP_DIFF(timestamp, LAG(timestamp) OVER (ORDER BY timestamp), MINUTE) AS time_diff_min\n",
        "  FROM\n",
        "    `bigquery-public-data.crypto_bitcoin_cash.blocks`\n",
        ")\n",
        "\n",
        "SELECT\n",
        "  DATE(timestamp) AS date,\n",
        "  AVG(time_diff_min) AS avg_time_diff_min\n",
        "FROM block_times\n",
        "WHERE time_diff_min IS NOT NULL\n",
        "GROUP BY date\n",
        "ORDER BY date\n",
        "\"\"\"\n",
        "df3 = client.query(query3).result().to_dataframe()"
      ],
      "metadata": {
        "id": "fvhzvJkseld1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "px.line(df3, x='date', y='avg_time_diff_min', title='Average Time Between Blocks (Minutes)').show()"
      ],
      "metadata": {
        "id": "Dz0zGKGUe1Sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The average time between Bitsoin blocks has remained fairly consistent around the expected target of 10 min, especially after 2010. However, there were a few significant spikes--most notably before 2010 and around 2017 -- where the time between blocks dramatically increased. These spikes may indicate early network instability or difficulty adjustment issues during periods of extreme mining activity or reduced hash rate."
      ],
      "metadata": {
        "id": "954O72Ns-I0s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictive Modeling"
      ],
      "metadata": {
        "id": "KqJS9ab0gP_4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query and Prepare the Data"
      ],
      "metadata": {
        "id": "g0W_yHy8hqFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "WITH block_data AS (\n",
        "  SELECT\n",
        "    size,\n",
        "    weight,\n",
        "    version,\n",
        "    number,\n",
        "    nonce,\n",
        "    TIMESTAMP_DIFF(timestamp, LAG(timestamp) OVER (ORDER BY timestamp), SECOND) AS time_since_last_block\n",
        "  FROM `bigquery-public-data.crypto_bitcoin_cash.blocks`\n",
        ")\n",
        "SELECT *\n",
        "FROM block_data\n",
        "WHERE time_since_last_block IS NOT NULL\n",
        "  AND size IS NOT NULL\n",
        "\n",
        "LIMIT 5000\n",
        "\"\"\"\n",
        "df = client.query(query).result().to_dataframe()\n",
        "df = df.drop(columns=['weight'])\n",
        "df = df.dropna()\n",
        "df['label'] = (df['size'] > 500000).astype(int)\n",
        "print(df.shape)\n",
        "print(df['label'].value_counts())"
      ],
      "metadata": {
        "id": "z63TU5iSi-O0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train/Test Split and Feature Prep"
      ],
      "metadata": {
        "id": "9rhI9gmBhKrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Features and target\n",
        "X = df[[ 'version', 'number',  'time_since_last_block']]\n",
        "y = df['label']\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "-_H6Mz9LgVfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train & Evaluate a Decision Tree Classifier"
      ],
      "metadata": {
        "id": "vZPQ222khOHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Initialize and train the model\n",
        "tree_model = DecisionTreeClassifier(random_state=42)\n",
        "tree_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = tree_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Optional: Visualize confusion matrix\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n"
      ],
      "metadata": {
        "id": "EH0NlQYuhMyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Model Evaluation Summary\n",
        "-------------------------\n",
        "We trained a Decision Tree Classifier to predict whether a block size exceeds 500KB.\n",
        "The model achieved an accuracy of approximately 91% on the test set.\")\n",
        "\n",
        "Key metrics:\n",
        "- Precision (Class 1): 0.79 â€” Of all blocks predicted as large, 79% were actually large.\n",
        "- Recall (Class 1): 0.80 â€” The model correctly identified 80% of actual large blocks.\n",
        "- F1-score (Class 1): 0.79 â€” Balanced performance on precision and recall for large blocks.\n",
        "\n",
        "The confusion matrix shows:\n",
        "- True Negatives: 733\n",
        "- False Positives: 47\n",
        "- False Negatives: 45\n",
        "- True Positives: 175\n",
        "\n",
        "The model performs well overall, with stronger accuracy on the majority class.\")\n",
        "It can be improved by trying techniques like hyperparameter tuning or using ensemble models.\n",
        "\n"
      ],
      "metadata": {
        "id": "O8it45ueQp7J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Managerial Insights and Takeaways\n",
        "----------------------------------\n",
        "1. **Blockchain block size is predictable using metadata:**\n",
        "   Variables like block version, position (number), and time between blocks\n",
        "   offer meaningful signals that can help anticipate whether a block will be large.\n",
        "\n",
        "2. **Machine learning can effectively support blockchain analysis:**\n",
        "   The decision tree model achieved 91% accuracy, suggesting that predictive models\n",
        "   can be used for monitoring, optimization, or anomaly detection in blockchain operations.\n",
        "\n",
        "3. **Operational planning opportunities for network scalability:**\n",
        "   Knowing which blocks are likely to be large may help miners or network operators\n",
        "   better manage bandwidth, node performance, and transaction prioritization.\n",
        "\n",
        "4. **Model interpretability supports decision-making:**\n",
        "   The decision tree model is transparent, making it easier to explain to stakeholders\n",
        "   and adapt into rule-based systems or dashboards.\n",
        "\n",
        "5. **Data from public sources like BigQuery can power real insights:**\n",
        "   This project demonstrates how publicly available blockchain data can be\n",
        "   leveraged for business intelligence and innovation."
      ],
      "metadata": {
        "id": "Mtkf5sA3SXxh"
      }
    }
  ]
}