{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "GWxdyb9NmE_v",
        "7NW8x5Vfm2VP",
        "7Oh1eR9ymPJj",
        "3nHDapHMde6o",
        "xPtvdYNPeZ6-",
        "JBSa2QaIeb20",
        "gR5soXWUehie",
        "KqJS9ab0gP_4",
        "ABL6Gt35nBL-"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Packages & Environment Setup"
      ],
      "metadata": {
        "id": "GWxdyb9NmE_v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "gRKUg9RZYcF3"
      },
      "outputs": [],
      "source": [
        "!pip install pandas-gbq --quiet\n",
        "!pip install google-cloud-bigquery pandas\n",
        "!pip install --quiet google-cloud-bigquery\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import pandas as pd\n",
        "from pandas.io import gbq\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "from google.cloud import bigquery"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EXECUTIVE SUMMARY"
      ],
      "metadata": {
        "id": "7NW8x5Vfm2VP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def executive_summary():\n",
        "    print(\"Executive Summary\")\n",
        "    print(\"------------------\")\n",
        "    print(\"This project explores the Bitcoin Cash blockchain by analyzing block-level data using BigQuery.\")\n",
        "    print(\"Our primary objective was to build a predictive model that determines whether a block exceeds\")\n",
        "    print(\"500KB in size based on metadata such as block version, number, and time since the previous block.\")\n",
        "    print()\n",
        "    print(\"After cleaning and preparing 5,000 rows of blockchain data, we trained a Decision Tree Classifier.\")\n",
        "    print(\"The model achieved strong performance with an overall test accuracy of 91%.\")\n",
        "    print()\n",
        "    print(\"Key results:\")\n",
        "    print(\"- Precision (for large blocks): 0.79\")\n",
        "    print(\"- Recall (for large blocks): 0.80\")\n",
        "    print(\"- F1-score (for large blocks): 0.79\")\n",
        "    print()\n",
        "    print(\"The model demonstrates solid predictive power and highlights potential for deeper analysis\")\n",
        "    print(\"on blockchain behavior using machine learning techniques. Future improvements could include\")\n",
        "    print(\"tuning model hyperparameters, testing ensemble models, or analyzing trends across time windows.\")\n",
        "\n",
        "executive_summary()\n"
      ],
      "metadata": {
        "id": "uFzcd-RLm5LP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project Connection"
      ],
      "metadata": {
        "id": "7Oh1eR9ymPJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "project_id = 'proven-wavelet-457219-u4'\n",
        "client = bigquery.Client(project = project_id)"
      ],
      "metadata": {
        "id": "gnehczJUZW5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Description & Preview"
      ],
      "metadata": {
        "id": "3nHDapHMde6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def describe_dataset():\n",
        "    print(\"Dataset Description\")\n",
        "    print(\"--------------------\")\n",
        "    print(\"The dataset used in this project is sourced from BigQuery’s public dataset:\")\n",
        "    print(\"`bigquery-public-data.crypto_bitcoin_cash.blocks`.\")\n",
        "    print()\n",
        "    print(\"Each row in the dataset represents a block on the Bitcoin Cash blockchain.\")\n",
        "    print(\"The following variables were selected for modeling:\")\n",
        "    print(\"- size: The size of the block in bytes (used to create the target variable).\")\n",
        "    print(\"- version: The block version number.\")\n",
        "    print(\"- number: The block height (its position in the chain).\")\n",
        "    print(\"- nonce: A value miners vary to find a valid hash (excluded from final model).\")\n",
        "    print(\"- time_since_last_block: Time difference (in seconds) between this and the previous block.\")\n",
        "    print()\n",
        "    print(\"The target variable `label` was engineered as a binary indicator:\")\n",
        "    print(\"- 1 if the block size > 500,000 bytes\")\n",
        "    print(\"- 0 otherwise\")\n",
        "    print()\n",
        "    print(\"After filtering and cleaning, the final dataset contains 5,000 rows and 4 predictor features.\")\n",
        "    print(\"This dataset was suitable for a binary classification task.\")\n",
        "\n",
        "describe_dataset()\n"
      ],
      "metadata": {
        "id": "U-_dACRcms1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "SELECT *\n",
        "FROM `bigquery-public-data.crypto_bitcoin_cash.blocks`\n",
        "LIMIT 10\n",
        "\"\"\"\n",
        "\n",
        "result = client.query(query).result().to_dataframe()\n",
        "result.head()"
      ],
      "metadata": {
        "id": "4OwG3nLTddVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA RESULTS and VISUALS"
      ],
      "metadata": {
        "id": "cB73URsNfn6z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Query 1: Block sizes over time"
      ],
      "metadata": {
        "id": "xPtvdYNPeZ6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query1 = \"\"\"\n",
        "SELECT\n",
        "  DATE(timestamp) AS date,\n",
        "  AVG(size) AS avg_block_size\n",
        "FROM `bigquery-public-data.crypto_bitcoin_cash.blocks`\n",
        "GROUP BY date\n",
        "ORDER BY date\n",
        "\"\"\"\n",
        "df1 = client.query(query1).result().to_dataframe()"
      ],
      "metadata": {
        "id": "c5Qc7y2reXQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "px.line(df1, x='date', y='avg_block_size', title='Average Block Size Over Time').show()"
      ],
      "metadata": {
        "id": "j5dvwv_RephB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Query 2: Number of blocks per day"
      ],
      "metadata": {
        "id": "JBSa2QaIeb20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query2 = \"\"\"\n",
        "SELECT\n",
        "  DATE(timestamp) AS date,\n",
        "  COUNT(*) AS block_count\n",
        "FROM `bigquery-public-data.crypto_bitcoin_cash.blocks`\n",
        "GROUP BY date\n",
        "ORDER BY date\n",
        "\"\"\"\n",
        "df2 = client.query(query2).result().to_dataframe()"
      ],
      "metadata": {
        "id": "H9IMnRjaeeUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "px.line(df2, x='date', y='block_count', title='Number of Blocks Per Day').show()"
      ],
      "metadata": {
        "id": "qDe-oUF0euS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Query 3: Average time between blocks"
      ],
      "metadata": {
        "id": "gR5soXWUehie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query3 = \"\"\"\n",
        "WITH block_times AS (\n",
        "  SELECT\n",
        "    timestamp,\n",
        "    TIMESTAMP_DIFF(timestamp, LAG(timestamp) OVER (ORDER BY timestamp), MINUTE) AS time_diff_min\n",
        "  FROM\n",
        "    `bigquery-public-data.crypto_bitcoin_cash.blocks`\n",
        ")\n",
        "\n",
        "SELECT\n",
        "  DATE(timestamp) AS date,\n",
        "  AVG(time_diff_min) AS avg_time_diff_min\n",
        "FROM block_times\n",
        "WHERE time_diff_min IS NOT NULL\n",
        "GROUP BY date\n",
        "ORDER BY date\n",
        "\"\"\"\n",
        "df3 = client.query(query3).result().to_dataframe()"
      ],
      "metadata": {
        "id": "fvhzvJkseld1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "px.line(df3, x='date', y='avg_time_diff_min', title='Average Time Between Blocks (Minutes)').show()"
      ],
      "metadata": {
        "id": "Dz0zGKGUe1Sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictive Modeling"
      ],
      "metadata": {
        "id": "KqJS9ab0gP_4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query and Prepare the Data"
      ],
      "metadata": {
        "id": "g0W_yHy8hqFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "WITH block_data AS (\n",
        "  SELECT\n",
        "    size,\n",
        "    weight,\n",
        "    version,\n",
        "    number,\n",
        "    nonce,\n",
        "    TIMESTAMP_DIFF(timestamp, LAG(timestamp) OVER (ORDER BY timestamp), SECOND) AS time_since_last_block\n",
        "  FROM `bigquery-public-data.crypto_bitcoin_cash.blocks`\n",
        ")\n",
        "SELECT *\n",
        "FROM block_data\n",
        "WHERE time_since_last_block IS NOT NULL\n",
        "  AND size IS NOT NULL\n",
        "\n",
        "LIMIT 5000\n",
        "\"\"\"\n",
        "df = client.query(query).result().to_dataframe()\n",
        "df = df.drop(columns=['weight'])\n",
        "df = df.dropna()\n",
        "df['label'] = (df['size'] > 500000).astype(int)\n",
        "print(df.shape)\n",
        "print(df['label'].value_counts())"
      ],
      "metadata": {
        "id": "z63TU5iSi-O0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train/Test Split and Feature Prep"
      ],
      "metadata": {
        "id": "9rhI9gmBhKrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Features and target\n",
        "X = df[[ 'version', 'number',  'time_since_last_block']]\n",
        "y = df['label']\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "-_H6Mz9LgVfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train & Evaluate a Decision Tree Classifier"
      ],
      "metadata": {
        "id": "vZPQ222khOHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Initialize and train the model\n",
        "tree_model = DecisionTreeClassifier(random_state=42)\n",
        "tree_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = tree_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Optional: Visualize confusion matrix\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n"
      ],
      "metadata": {
        "id": "EH0NlQYuhMyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model_performance():\n",
        "    print(\"Model Evaluation Summary\")\n",
        "    print(\"-------------------------\")\n",
        "    print(\"We trained a Decision Tree Classifier to predict whether a block size exceeds 500KB.\")\n",
        "    print(\"The model achieved an accuracy of approximately 91% on the test set.\")\n",
        "    print()\n",
        "    print(\"Key metrics:\")\n",
        "    print(\"- Precision (Class 1): 0.79 — Of all blocks predicted as large, 79% were actually large.\")\n",
        "    print(\"- Recall (Class 1): 0.80 — The model correctly identified 80% of actual large blocks.\")\n",
        "    print(\"- F1-score (Class 1): 0.79 — Balanced performance on precision and recall for large blocks.\")\n",
        "    print()\n",
        "    print(\"The confusion matrix shows:\")\n",
        "    print(\"- True Negatives: 733\")\n",
        "    print(\"- False Positives: 47\")\n",
        "    print(\"- False Negatives: 45\")\n",
        "    print(\"- True Positives: 175\")\n",
        "    print()\n",
        "    print(\"The model performs well overall, with stronger accuracy on the majority class.\")\n",
        "    print(\"It can be improved by trying techniques like hyperparameter tuning or using ensemble models.\")\n",
        "\n",
        "evaluate_model_performance()\n"
      ],
      "metadata": {
        "id": "42tlRwSilb_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Managerial insights and takeaways"
      ],
      "metadata": {
        "id": "ABL6Gt35nBL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def managerial_takeaways():\n",
        "    print(\"Managerial Insights and Takeaways\")\n",
        "    print(\"----------------------------------\")\n",
        "    print(\"1. **Blockchain block size is predictable using metadata:**\")\n",
        "    print(\"   Variables like block version, position (number), and time between blocks\")\n",
        "    print(\"   offer meaningful signals that can help anticipate whether a block will be large.\")\n",
        "    print()\n",
        "    print(\"2. **Machine learning can effectively support blockchain analysis:**\")\n",
        "    print(\"   The decision tree model achieved 91% accuracy, suggesting that predictive models\")\n",
        "    print(\"   can be used for monitoring, optimization, or anomaly detection in blockchain operations.\")\n",
        "    print()\n",
        "    print(\"3. **Operational planning opportunities for network scalability:**\")\n",
        "    print(\"   Knowing which blocks are likely to be large may help miners or network operators\")\n",
        "    print(\"   better manage bandwidth, node performance, and transaction prioritization.\")\n",
        "    print()\n",
        "    print(\"4. **Model interpretability supports decision-making:**\")\n",
        "    print(\"   The decision tree model is transparent, making it easier to explain to stakeholders\")\n",
        "    print(\"   and adapt into rule-based systems or dashboards.\")\n",
        "    print()\n",
        "    print(\"5. **Data from public sources like BigQuery can power real insights:**\")\n",
        "    print(\"   This project demonstrates how publicly available blockchain data can be\")\n",
        "    print(\"   leveraged for business intelligence and innovation.\")\n",
        "\n",
        "managerial_takeaways()\n"
      ],
      "metadata": {
        "id": "t08XvxeWnCsD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}